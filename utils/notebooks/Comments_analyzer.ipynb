{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0VLDkGfZpCT",
        "outputId": "4e3bb60a-0bb6-43a3-bca1-41c64c1efa26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.3.19)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain_google_genai) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain_google_genai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain_google_genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain_google_genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.6-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain_google_genai\n",
            "Successfully installed filetype-1.2.0 langchain_google_genai-2.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joMH5ETcZHZk",
        "outputId": "4fe6339e-2d49-4978-f1bf-fb8775fc72ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"total_comments\": 5,\n",
            "  \"sentiment_analysis\": {\n",
            "    \"positive_ratio\": 0.6,\n",
            "    \"negative_ratio\": 0.4,\n",
            "    \"avg_confidence\": 0.9997121810913085\n",
            "  },\n",
            "  \"topic_distribution\": {\n",
            "    \"professional\": 0.6739587783813477,\n",
            "    \"entertainment\": 0.24131295084953308,\n",
            "    \"personal\": 0.047384753823280334,\n",
            "    \"technology\": 0.03617731109261513,\n",
            "    \"politics\": 0.0011661830358207226\n",
            "  },\n",
            "  \"gemini_insights\": {\n",
            "    \"overall_insights\": \"**1. Overall Themes**\\n* **Product Feedback:** Positive feedback on product features, negative feedback on customer service.\\n* **Current Events:** Commentary on political debates and technological advancements.\\n\\n**2. Key Insights**\\n\\n* **Product Features:** Users are highly satisfied with the product's functionality.\\n* **Customer Service:** There is dissatisfaction with the level of customer support provided.\\n* **Political Discontent:** Users express frustration with the repetitiveness and polarization of political discourse.\\n* **Technological Progress:** Users recognize and appreciate the rapid pace of technological innovation.\\n* **Software Updates:** Recent updates have been well-received by users, improving their experience.\\n\\n**3. Strategic Recommendations**\\n\\n* **Product Development:** Continue to enhance product features and functionality based on user feedback.\\n* **Customer Service Improvement:** Invest in improving customer service quality and responsiveness.\\n* **Political Engagement:** Consider providing platforms or initiatives for users to engage in meaningful political discussions beyond divisive debates.\\n* **Technological Innovation:** Continue to innovate and embrace new technologies to meet evolving user needs.\\n* **Software Updates:** Regularly release high-quality updates that address user concerns and improve the user experience.\\n* **Community Building:** Facilitate user communities or forums where users can share feedback, connect with each other, and participate in product development discussions.\"\n",
            "  },\n",
            "  \"most_positive_comment\": {\n",
            "    \"text\": \"This product is amazing! Really love the features.\",\n",
            "    \"label\": \"POSITIVE\",\n",
            "    \"score\": 0.9998879432678223\n",
            "  },\n",
            "  \"most_negative_comment\": {\n",
            "    \"text\": \"I'm disappointed with the customer service.\",\n",
            "    \"label\": \"NEGATIVE\",\n",
            "    \"score\": 0.999797523021698\n",
            "  },\n",
            "  \"top_3_positive_words\": [\n",
            "    \"amazing\",\n",
            "    \"love\",\n",
            "    \"great\"\n",
            "  ],\n",
            "  \"top_3_negative_words\": [\n",
            "    \"boring\",\n",
            "    \"disappointed\",\n",
            "    \"debate\"\n",
            "  ],\n",
            "  \"suggested_improvements\": \"**Product feedback:**\\n\\n* **Actionable suggestion:** Highlight specific features that the user loved and provide options for additional customization or enhancements.\\n\\n**Customer service feedback:**\\n\\n* **Actionable suggestion:** Apologize for the disappointing experience, investigate the issue, and provide a resolution or explanation.\\n\\n**Political content feedback:**\\n\\n* **Actionable suggestion:** Create a filter or moderation system to prevent political debates from dominating the platform.\\n\\n**Technology feedback:**\\n\\n* **Actionable suggestion:** Provide resources or updates on the latest technological advancements and their potential impact.\\n\\n**Update feedback:**\\n\\n* **Actionable suggestion:** Thank the user for the positive feedback and gather suggestions for further improvements or additional features in future updates.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Langchain and AI Libraries\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from transformers import pipeline\n",
        "\n",
        "class OverallCommentAnalyzer:\n",
        "    def __init__(self, google_api_key: str):\n",
        "        \"\"\"Initialize analyzer with Gemini and sentiment models\"\"\"\n",
        "        self.gemini_model = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-pro\",\n",
        "            google_api_key=google_api_key\n",
        "        )\n",
        "\n",
        "        self.sentiment_model = pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "        )\n",
        "\n",
        "        self.topic_model = pipeline(\n",
        "            \"zero-shot-classification\",\n",
        "            model=\"facebook/bart-large-mnli\"\n",
        "        )\n",
        "\n",
        "    def overall_sentiment_analysis(self, comments: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"Compute overall sentiment across comments\"\"\"\n",
        "        sentiments = [self.sentiment_model(comment)[0] for comment in comments]\n",
        "\n",
        "        return {\n",
        "            \"positive_ratio\": sum(1 for s in sentiments if s['label'] == 'POSITIVE') / len(sentiments),\n",
        "            \"negative_ratio\": sum(1 for s in sentiments if s['label'] == 'NEGATIVE') / len(sentiments),\n",
        "            \"avg_confidence\": np.mean([s['score'] for s in sentiments])\n",
        "        }\n",
        "\n",
        "    def overall_topic_analysis(self, comments: List[str]) -> Dict[str, float]:\n",
        "        \"\"\"Classify overall topics across comments\"\"\"\n",
        "        categories = [\"technology\", \"politics\", \"personal\", \"professional\", \"entertainment\"]\n",
        "\n",
        "        # Perform zero-shot classification\n",
        "        result = self.topic_model(\n",
        "            comments[0] if comments else \"\",\n",
        "            categories\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            label: float(score)\n",
        "            for label, score in zip(result['labels'], result['scores'])\n",
        "        }\n",
        "\n",
        "    def additional_comment_analysis(self, comments: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"Perform additional detailed comment analysis\"\"\"\n",
        "        # Analyze individual comment sentiments\n",
        "        comment_sentiments = []\n",
        "        for comment in comments:\n",
        "            sentiment = self.sentiment_model(comment)[0]\n",
        "            comment_sentiments.append({\n",
        "                \"text\": comment,\n",
        "                \"label\": sentiment['label'],\n",
        "                \"score\": sentiment['score']\n",
        "            })\n",
        "\n",
        "        # Find most positive and negative comments\n",
        "        most_positive = max(\n",
        "            [c for c in comment_sentiments if c['label'] == 'POSITIVE'],\n",
        "            key=lambda x: x['score'],\n",
        "            default={\"text\": \"No positive comments\", \"score\": 0}\n",
        "        )\n",
        "\n",
        "        most_negative = max(\n",
        "            [c for c in comment_sentiments if c['label'] == 'NEGATIVE'],\n",
        "            key=lambda x: x['score'],\n",
        "            default={\"text\": \"No negative comments\", \"score\": 0}\n",
        "        )\n",
        "\n",
        "        # Analyze most positive and negative words\n",
        "        def extract_words(comments):\n",
        "            words = []\n",
        "            for comment in comments:\n",
        "                # Clean and tokenize words\n",
        "                clean_words = re.findall(r'\\w+', comment.lower())\n",
        "                words.extend([word for word in clean_words if len(word) > 2])\n",
        "            return words\n",
        "\n",
        "        all_words = extract_words(comments)\n",
        "        word_counts = Counter(all_words)\n",
        "\n",
        "        # Find most positive and negative words\n",
        "        def word_sentiment(word):\n",
        "            try:\n",
        "                return self.sentiment_model([word])[0]\n",
        "            except:\n",
        "                return {\"label\": \"NEUTRAL\", \"score\": 0}\n",
        "\n",
        "        word_sentiments = {\n",
        "            word: word_sentiment(word) for word in set(all_words)\n",
        "        }\n",
        "\n",
        "        positive_words = sorted(\n",
        "            [w for w, s in word_sentiments.items() if s['label'] == 'POSITIVE'],\n",
        "            key=lambda w: (word_sentiments[w]['score'], word_counts[w]),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        negative_words = sorted(\n",
        "            [w for w, s in word_sentiments.items() if s['label'] == 'NEGATIVE'],\n",
        "            key=lambda w: (word_sentiments[w]['score'], word_counts[w]),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # Gemini improvement suggestions\n",
        "        prompt = PromptTemplate(\n",
        "            input_variables=[\"comments\"],\n",
        "            template=\"\"\"Provide specific, actionable improvement suggestions based on these comments:\n",
        "            {comments}\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        chain = LLMChain(llm=self.gemini_model, prompt=prompt)\n",
        "        improvements = chain.run(comments=\"\\n\".join(comments))\n",
        "\n",
        "        return {\n",
        "            \"most_positive_comment\": most_positive,\n",
        "            \"most_negative_comment\": most_negative,\n",
        "            \"top_3_positive_words\": positive_words[:3],\n",
        "            \"top_3_negative_words\": negative_words[:3],\n",
        "            \"suggested_improvements\": improvements\n",
        "        }\n",
        "\n",
        "    def gemini_comprehensive_analysis(self, comments: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"Perform comprehensive analysis using Gemini\"\"\"\n",
        "        prompt = PromptTemplate(\n",
        "            input_variables=[\"comments\"],\n",
        "            template=\"\"\"Analyze the following comments comprehensively:\n",
        "            1. Identify overall themes\n",
        "            2. Summarize key insights\n",
        "            3. Provide strategic recommendations\n",
        "\n",
        "            Comments: {comments}\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        chain = LLMChain(llm=self.gemini_model, prompt=prompt)\n",
        "        return {\"overall_insights\": chain.run(comments=\"\\n\".join(comments))}\n",
        "\n",
        "    def analyze_comments(self, comments: List[str]) -> str:\n",
        "        \"\"\"Perform comprehensive overall analysis\"\"\"\n",
        "        analysis = {\n",
        "            \"total_comments\": len(comments),\n",
        "            \"sentiment_analysis\": self.overall_sentiment_analysis(comments),\n",
        "            \"topic_distribution\": self.overall_topic_analysis(comments),\n",
        "            \"gemini_insights\": self.gemini_comprehensive_analysis(comments),\n",
        "            **self.additional_comment_analysis(comments)\n",
        "        }\n",
        "\n",
        "        return json.dumps(analysis, indent=2)\n",
        "\n",
        "def main():\n",
        "    google_api_key = \"AIzaSyDFCC3WxFXkar2cuZWBLNkFweuzIVB1hRE\"\n",
        "    analyzer = OverallCommentAnalyzer(google_api_key)\n",
        "\n",
        "    sample_comments = [\n",
        "        \"This product is amazing! Really love the features.\",\n",
        "        \"I'm disappointed with the customer service.\",\n",
        "        \"Another boring political debate happening again.\",\n",
        "        \"Technology is changing so fast these days!\",\n",
        "        \"Great experience with the new update.\"\n",
        "    ]\n",
        "\n",
        "    overall_analysis = analyzer.analyze_comments(sample_comments)\n",
        "    print(overall_analysis)\n",
        "\n",
        "    with open(\"overall_comment_analysis.json\", \"w\") as f:\n",
        "        f.write(overall_analysis)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}